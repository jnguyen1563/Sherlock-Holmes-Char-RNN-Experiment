{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Attention, Dense, Embedding, GRU, LSTM, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs available:  1\n"
     ]
    }
   ],
   "source": [
    "# Ensure GPU is being recognized\n",
    "print(\"Num GPUs available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in text file\n",
    "with open('sherlock.txt', 'r', encoding='utf-8') as f:\n",
    "    sherlock_data = f.read()\n",
    "\n",
    "# Remove the 'table of contents' and start with stories\n",
    "sherlock_data = sherlock_data[3376:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data: 3378552 characters\n",
      "Number of unique characters: 97\n",
      "Unique Characters: ['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '£', '°', '½', 'ß', 'à', 'â', 'è', 'é', 'ê', 'î', 'ñ', 'ô', 'ö', 'û', 'ü', '’']\n"
     ]
    }
   ],
   "source": [
    "# Dataset information\n",
    "print(f'Length of data: {len(sherlock_data)} characters')\n",
    "unique_chars = sorted(set(sherlock_data))\n",
    "print(f'Number of unique characters: {len(unique_chars)}')\n",
    "print(f'Unique Characters: {unique_chars}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          CHAPTER I\n",
      "          Mr. Sherlock Holmes\n",
      "\n",
      "\n",
      "     In the year 1878 I took my degree of Doctor of Medicine of the\n",
      "     University of London, and proceeded to Netley to go through the\n",
      "     course prescribed for surgeons in the army. Having completed my\n",
      "     studies there, I was duly attached to the Fifth Northumberland\n",
      "     Fusiliers as Assistant Surgeon. The regiment was stationed in India\n",
      "     at the time, and before I could join it, the second Afghan war had\n",
      "     broken out. On landing a\n"
     ]
    }
   ],
   "source": [
    "# Preview first 1000 characters\n",
    "print(sherlock_data[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character Representation:  Mr. Sherlock\n",
      "Integer Representation:  [38 72 11  1 44 62 59 72 66 69 57 65]\n"
     ]
    }
   ],
   "source": [
    "# Encode characters for training\n",
    "index_mapping = {char:i for i, char in enumerate(unique_chars)}\n",
    "sherlock_index = np.array([index_mapping[char] for char in sherlock_data]) # map features to index\n",
    "char_index = np.array(unique_chars)\n",
    "\n",
    "print('Character Representation: ',sherlock_data[30:42])\n",
    "print('Integer Representation: ', sherlock_index[30:42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset from slices of Sherlock data\n",
    "dataset_slices = tf.data.Dataset.from_tensor_slices(sherlock_index)\n",
    "\n",
    "# Separate text into sequences\n",
    "seq_len = 100\n",
    "examples_per_epoch = int(len(sherlock_data)/(seq_len+1))\n",
    "sequences = dataset_slices.batch(seq_len+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split sequences into input and target sequences\n",
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Break dataset into batches\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model constants\n",
    "vocab_size = len(unique_chars)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build RNN with GRU\n",
    "def build_GRU_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           24832     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 97)            99425     \n",
      "=================================================================\n",
      "Total params: 4,062,561\n",
      "Trainable params: 4,062,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = build_GRU_model(vocab_size=len(unique_chars),\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units,\n",
    "                    batch_size=BATCH_SIZE)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sparse categorical crossentropy as loss\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoints to access weights later\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_{epoch}')\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "                                                        save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 522 steps\n",
      "Epoch 1/15\n",
      "522/522 [==============================] - 45s 86ms/step - loss: 2.0117\n",
      "Epoch 2/15\n",
      "522/522 [==============================] - 41s 78ms/step - loss: 1.3587\n",
      "Epoch 3/15\n",
      "522/522 [==============================] - 41s 78ms/step - loss: 1.2250\n",
      "Epoch 4/15\n",
      "522/522 [==============================] - 41s 79ms/step - loss: 1.1649\n",
      "Epoch 5/15\n",
      "522/522 [==============================] - 41s 79ms/step - loss: 1.1263\n",
      "Epoch 6/15\n",
      "522/522 [==============================] - 41s 78ms/step - loss: 1.0970\n",
      "Epoch 7/15\n",
      "522/522 [==============================] - 41s 78ms/step - loss: 1.0731\n",
      "Epoch 8/15\n",
      "522/522 [==============================] - 40s 76ms/step - loss: 1.0519\n",
      "Epoch 9/15\n",
      "522/522 [==============================] - 39s 74ms/step - loss: 1.0331\n",
      "Epoch 10/15\n",
      "522/522 [==============================] - 40s 77ms/step - loss: 1.0166\n",
      "Epoch 11/15\n",
      "522/522 [==============================] - 40s 76ms/step - loss: 1.0015\n",
      "Epoch 12/15\n",
      "522/522 [==============================] - 40s 77ms/step - loss: 0.9872\n",
      "Epoch 13/15\n",
      "522/522 [==============================] - 42s 80ms/step - loss: 0.9752\n",
      "Epoch 14/15\n",
      "522/522 [==============================] - 42s 81ms/step - loss: 0.9637\n",
      "Epoch 15/15\n",
      "522/522 [==============================] - 42s 80ms/step - loss: 0.9539\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "EPOCHS = 15\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_GRU_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            24832     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 97)             99425     \n",
      "=================================================================\n",
      "Total params: 4,062,561\n",
      "Trainable params: 4,062,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, num_generate=1000, temperature=1.0):\n",
    "    input_eval = [index_mapping[c] for c in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "    generated_text = []\n",
    "    \n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        \n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "        \n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        generated_text.append(char_index[predicted_id])\n",
    "        \n",
    "    return(start_string + ''.join(generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was Mr. Reuland I\n",
      "     should not have something to decrepatid you will fail to tell you than I.\n",
      "\n",
      "     \"'That with a shrink hat one\n",
      "     generally is looking at the apologiency quite a bit.\n",
      "     They appeared.\n",
      "\n",
      "     Let it threatened by their light her for the tragedy.\n",
      "\n",
      "     \"When a man on the Underground, outwin lire adjustivess\n",
      "     into the garret was able body and should hive reached this\n",
      "     creature upon this mental detach.\"\n",
      "\n",
      "     \"That was the use of the express be put down your lather has\n",
      "     been mistaken, but as I heard often and I was filled into it. I gather that he\n",
      "     walked so hu round, though I can be rather belay to be an idea. The case besides, with a wooden saw the enormous\n",
      "     reason why did you expect Dr. Professor Coram, will bring a\n",
      "     return back to have been into the matter so such an unfortunate Manor of the tould\n",
      "     of us out of the latesteeparis again, Dr  round the room caught the edme baskets. Fou before ever you want to\n",
      "     introduce mutton, that\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u'There '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build RNN with LSTM\n",
    "def build_LSTM_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (64, None, 256)           24832     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (64, None, 97)            99425     \n",
      "=================================================================\n",
      "Total params: 5,371,233\n",
      "Trainable params: 5,371,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = build_LSTM_model(vocab_size=len(unique_chars),\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units,\n",
    "                    batch_size=BATCH_SIZE)\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 522 steps\n",
      "Epoch 1/15\n",
      "522/522 [==============================] - 51s 98ms/step - loss: 1.9141\n",
      "Epoch 2/15\n",
      "522/522 [==============================] - 50s 96ms/step - loss: 1.3445\n",
      "Epoch 3/15\n",
      "522/522 [==============================] - 50s 95ms/step - loss: 1.2229\n",
      "Epoch 4/15\n",
      "522/522 [==============================] - 49s 94ms/step - loss: 1.1641\n",
      "Epoch 5/15\n",
      "522/522 [==============================] - 49s 94ms/step - loss: 1.1261\n",
      "Epoch 6/15\n",
      "522/522 [==============================] - 49s 94ms/step - loss: 1.0971 1s -\n",
      "Epoch 7/15\n",
      "522/522 [==============================] - 49s 95ms/step - loss: 1.0723\n",
      "Epoch 8/15\n",
      "522/522 [==============================] - 49s 93ms/step - loss: 1.0506\n",
      "Epoch 9/15\n",
      "522/522 [==============================] - 50s 95ms/step - loss: 1.0313\n",
      "Epoch 10/15\n",
      "522/522 [==============================] - 51s 97ms/step - loss: 1.0119\n",
      "Epoch 11/15\n",
      "522/522 [==============================] - 53s 101ms/step - loss: 0.9946\n",
      "Epoch 12/15\n",
      "522/522 [==============================] - 50s 97ms/step - loss: 0.9776\n",
      "Epoch 13/15\n",
      "522/522 [==============================] - 50s 97ms/step - loss: 0.9612\n",
      "Epoch 14/15\n",
      "522/522 [==============================] - 51s 98ms/step - loss: 0.9449\n",
      "Epoch 15/15\n",
      "522/522 [==============================] - 49s 94ms/step - loss: 0.9294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x202c122f688>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save_weights('./training_checkpoints/LSTM_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = build_LSTM_model(vocab_size=len(unique_chars),\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units,\n",
    "                    batch_size=1)\n",
    "\n",
    "model2.load_weights('./training_checkpoints/LSTM_checkpoint')\n",
    "model2.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (1, None, 256)            24832     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (1, None, 1024)           5246976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (1, None, 97)             99425     \n",
      "=================================================================\n",
      "Total params: 5,371,233\n",
      "Trainable params: 5,371,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There got away into the house,\" said Holmes. \"I wion my friend jealous, as you tell me\n",
      "     that he and I have seen anything more like a long one to applause. It was\n",
      "     some story of the middle of it.\n",
      "\n",
      "     \"What is it, then?\"\n",
      "\n",
      "     \"Well, you dejected that, there would be all that is better thanks.\"\n",
      "\n",
      "     There was a few months back to the neck in front. Take my ears as I\n",
      "     ended by crumpling of the sharing brow.  The afternoon was in\n",
      "     Mortimer Spanish desires. I understood that we shall show you to the Franco-Midland\n",
      "     Hill.\"\n",
      "\n",
      "     \"There is.\"\n",
      "\n",
      "     \"It was I have no means of geores buttons upon a new base, and he\n",
      "     was regomsed for a money and took a\n",
      "     stream of fierce-eyed, wicked chindering from as to their\n",
      "     business. It has been committed in the outside-shever. There's no one their own\n",
      "     countries from a clothes does. It ran\n",
      "     argument which brought was married. A lady was\n",
      "     largely in an ordinary but, as the cloud of light in the doar, which lead\n",
      "     in\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model2, start_string='There '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build RNN with basic RNN implementation\n",
    "def build_RNN_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.SimpleRNN(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           24832     \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (64, None, 1024)          1311744   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 97)            99425     \n",
      "=================================================================\n",
      "Total params: 1,436,001\n",
      "Trainable params: 1,436,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = build_RNN_model(vocab_size=len(unique_chars),\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units,\n",
    "                    batch_size=BATCH_SIZE)\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 522 steps\n",
      "Epoch 1/15\n",
      "522/522 [==============================] - 39s 76ms/step - loss: 2.3600\n",
      "Epoch 2/15\n",
      "522/522 [==============================] - 38s 73ms/step - loss: 1.5849\n",
      "Epoch 3/15\n",
      "522/522 [==============================] - 38s 73ms/step - loss: 1.4032\n",
      "Epoch 4/15\n",
      "522/522 [==============================] - 38s 73ms/step - loss: 1.3186\n",
      "Epoch 5/15\n",
      "522/522 [==============================] - 38s 72ms/step - loss: 1.2687\n",
      "Epoch 6/15\n",
      "522/522 [==============================] - 38s 72ms/step - loss: 1.2363\n",
      "Epoch 7/15\n",
      "522/522 [==============================] - 38s 72ms/step - loss: 1.2128\n",
      "Epoch 8/15\n",
      "522/522 [==============================] - 38s 72ms/step - loss: 1.1940\n",
      "Epoch 9/15\n",
      "522/522 [==============================] - 38s 72ms/step - loss: 1.1788\n",
      "Epoch 10/15\n",
      "522/522 [==============================] - 38s 72ms/step - loss: 1.1659\n",
      "Epoch 11/15\n",
      "522/522 [==============================] - 38s 72ms/step - loss: 1.1556\n",
      "Epoch 12/15\n",
      "522/522 [==============================] - 38s 72ms/step - loss: 1.1460\n",
      "Epoch 13/15\n",
      "522/522 [==============================] - 38s 72ms/step - loss: 1.1379\n",
      "Epoch 14/15\n",
      "522/522 [==============================] - 38s 73ms/step - loss: 1.1307\n",
      "Epoch 15/15\n",
      "522/522 [==============================] - 38s 72ms/step - loss: 1.1244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14746279388>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.compile(optimizer='adam', loss=loss)\n",
    "model3.fit(dataset, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save_weights('./training_checkpoints/RNN_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = build_RNN_model(vocab_size=len(unique_chars),\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units,\n",
    "                    batch_size=1)\n",
    "model3.load_weights('./training_checkpoints/RNN_checkpoint')\n",
    "model3.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There LNd, I want of his pocket, I pessired bygeal.\n",
      "\n",
      "     \"A very solution.\"\n",
      "\n",
      "     \"In the colligants, and maid doubt the faces as it was there and something was evidently\n",
      "     had a most serious rest up, and\n",
      "     the weight would have had py\n",
      "     round with a very right had ruch for his mind.\n",
      "\n",
      "     Holmes stopped at our dark man's hand. A confession of the relacitions. I must assure no means, who had first might trie, there was a lossly barrates for with the door and shutters below any step had regret him should, had occasional\n",
      "     twission to\n",
      "     he live up to me that\n",
      "     they are brows most look in with convally last\n",
      "     things are in his eyes e might imagines we will seek-heavy staggerings and outside, house, as business may\n",
      "     believe to say that is the paper answered. ' and was\n",
      "     wrong. They saw that we are dealingshe\n",
      "     object to acced is too well within the room which seemed to me that I am a companion of Agent Prower McMurdo, but I shall suddenly staring up as his foolsca\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model3, start_string='There '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build RNN with both GRU and LSTM\n",
    "def build_LSTM_GRU_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                             return_sequences=True,\n",
    "                             stateful=True,\n",
    "                             recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (64, None, 256)           24832     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (64, None, 1024)          6297600   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (64, None, 97)            99425     \n",
      "=================================================================\n",
      "Total params: 11,668,833\n",
      "Trainable params: 11,668,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = build_LSTM_GRU_model(vocab_size=len(unique_chars),\n",
    "                              embedding_dim=embedding_dim,\n",
    "                              rnn_units=rnn_units,\n",
    "                              batch_size=BATCH_SIZE)\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 522 steps\n",
      "Epoch 1/15\n",
      "522/522 [==============================] - 158s 302ms/step - loss: 2.0433\n",
      "Epoch 2/15\n",
      "522/522 [==============================] - 157s 301ms/step - loss: 1.3121\n",
      "Epoch 3/15\n",
      "522/522 [==============================] - 153s 294ms/step - loss: 1.1957\n",
      "Epoch 4/15\n",
      "522/522 [==============================] - 153s 292ms/step - loss: 1.1404\n",
      "Epoch 5/15\n",
      "522/522 [==============================] - 155s 296ms/step - loss: 1.1017\n",
      "Epoch 6/15\n",
      "522/522 [==============================] - 158s 303ms/step - loss: 1.0710\n",
      "Epoch 7/15\n",
      "522/522 [==============================] - 164s 314ms/step - loss: 1.0423\n",
      "Epoch 8/15\n",
      "522/522 [==============================] - 163s 312ms/step - loss: 1.0144\n",
      "Epoch 9/15\n",
      "522/522 [==============================] - 153s 294ms/step - loss: 0.9877\n",
      "Epoch 10/15\n",
      "522/522 [==============================] - 162s 309ms/step - loss: 0.9599\n",
      "Epoch 11/15\n",
      "522/522 [==============================] - 161s 309ms/step - loss: 0.9334\n",
      "Epoch 12/15\n",
      "522/522 [==============================] - 155s 297ms/step - loss: 0.9064\n",
      "Epoch 13/15\n",
      "522/522 [==============================] - 155s 297ms/step - loss: 0.8799\n",
      "Epoch 14/15\n",
      "522/522 [==============================] - 156s 299ms/step - loss: 0.8544\n",
      "Epoch 15/15\n",
      "522/522 [==============================] - 155s 296ms/step - loss: 0.8304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x202c78cecc8>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.compile(optimizer='adam', loss=loss)\n",
    "model4.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.save_weights('./training_checkpoints/LSTM_GRU_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = build_LSTM_GRU_model(vocab_size=len(unique_chars),\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units,\n",
    "                    batch_size=1)\n",
    "model4.load_weights('./training_checkpoints/LSTM_GRU_checkpoint')\n",
    "model4.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was no one upon him?\"\n",
      "\n",
      "     Holmes nodded applied \"There, you name!\" said Holmes, \"I shall see him even sooner\n",
      "     there shared in the street. It loved means\n",
      "     that it was to far me, and his eyes fell go to keep her it upon the\n",
      "     ground followed by the mentte who had met Mr. Barclay lumps no\n",
      "     telegraph with it.\"\n",
      "\n",
      "     \"That you,\" said Holmes, smiling, answer in the exerces of the firm. Her\n",
      "     sleep would stand through my head, pael face, and against them, es\n",
      "     upon it, in spite of its\n",
      "     instrument.\n",
      "\n",
      "     \"Your own villainy,\" he white figure. \"Can't you, if you wonder to his ruin, and\n",
      "     running through the squasters?\"\n",
      "\n",
      "     \"Well, it is likely a little throughory at ten o'clock't.\n",
      "\n",
      "     Their keys and looked sternly at her excited, heard, high injury ty was a quick step now in it was\n",
      "     covered with the Navy, invite that they were told of my father\n",
      "     Barrymore of Napoleon, and his persuady has gone this idea. Nothing more showing than\n",
      "     singular knill I\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model4, start_string='There '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bidirectional_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(rnn_units // 2, return_sequences=True)),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (64, None, 256)           24832     \n",
      "_________________________________________________________________\n",
      "bidirectional_16 (Bidirectio (64, None, 1024)          3149824   \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (64, None, 97)            99425     \n",
      "=================================================================\n",
      "Total params: 3,274,081\n",
      "Trainable params: 3,274,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5 = build_bidirectional_model(vocab_size=len(unique_chars),\n",
    "                              embedding_dim=embedding_dim,\n",
    "                              rnn_units=rnn_units,\n",
    "                              batch_size=BATCH_SIZE)\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 522 steps\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.forward_layer.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.forward_layer.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.forward_layer.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.backward_layer.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.backward_layer.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.backward_layer.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.forward_layer.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.forward_layer.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.forward_layer.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.backward_layer.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.backward_layer.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.backward_layer.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "522/522 [==============================] - 40s 77ms/step - loss: 0.4897\n",
      "Epoch 2/15\n",
      "522/522 [==============================] - 37s 71ms/step - loss: 0.0239\n",
      "Epoch 3/15\n",
      "522/522 [==============================] - 37s 71ms/step - loss: 0.0211\n",
      "Epoch 4/15\n",
      "522/522 [==============================] - 37s 71ms/step - loss: 0.0198\n",
      "Epoch 5/15\n",
      "522/522 [==============================] - 37s 71ms/step - loss: 0.0187\n",
      "Epoch 6/15\n",
      "522/522 [==============================] - 38s 72ms/step - loss: 0.0178\n",
      "Epoch 7/15\n",
      "522/522 [==============================] - 38s 73ms/step - loss: 0.0170\n",
      "Epoch 8/15\n",
      "522/522 [==============================] - 38s 72ms/step - loss: 0.0162\n",
      "Epoch 9/15\n",
      "522/522 [==============================] - 38s 72ms/step - loss: 0.0154\n",
      "Epoch 10/15\n",
      "522/522 [==============================] - 38s 72ms/step - loss: 0.0145\n",
      "Epoch 11/15\n",
      "522/522 [==============================] - 37s 72ms/step - loss: 0.0135\n",
      "Epoch 12/15\n",
      "522/522 [==============================] - 37s 71ms/step - loss: 0.0124\n",
      "Epoch 13/15\n",
      "522/522 [==============================] - 37s 71ms/step - loss: 0.0111\n",
      "Epoch 14/15\n",
      "522/522 [==============================] - 38s 73ms/step - loss: 0.0095\n",
      "Epoch 15/15\n",
      "522/522 [==============================] - 37s 71ms/step - loss: 0.0078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x11dd7b3d248>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.compile(optimizer='adam', loss=loss)\n",
    "model5.fit(dataset, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.save_weights('./training_checkpoints/bidirectional_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = build_bidirectional_model(vocab_size=len(unique_chars),\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units,\n",
    "                    batch_size=1)\n",
    "model5.load_weights('./training_checkpoints/bidirectional_checkpoint')\n",
    "model5.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There hexalopexanythadves?\"\n",
      " tot vene livesumaringroxinemy'HAmond\n",
      " llene.\n",
      " rFPreneneme, menfedonenebes\n",
      " H fatonodenetha\n",
      " mivenemermey\n",
      "\n",
      " nexar--I Brivesananes cèinèSclvif Miny -d\n",
      " stesad benereöGeereve mensAnenCin tingy petoréAsus°à’üI fa winotesed Pon'din bfined mesinYonen.\n",
      " anexadrenoxpare, I oborexarineme! Wmes?\"I ugen Ohhexaloro-Clinsunea mexarinelachestealenx½edI Yoryon, us.\n",
      " finncimalifid--cr`'Tresthevedrvenendzzzzzzzzzzzzzzzeneshancorend.\n",
      " agy, junearZVelinemes'm, Cagrex Agy t y udwabobes; sveved, Chiswhemenesmady cudd.\n",
      " Y.\n",
      " ddy taloponellemed finerenobal½?½Dy I sishen'sos, Trabunefey hes'Ja minere.\n",
      " *7lin ItenoneGonconanequncrineperinenennd mesmuneshe'Slaîtowad\n",
      " umery Heroushachelo,  necloryotoggreswime ey he! gringes manenedas, fusony\n",
      " bin'Siny.\n",
      " Cine ocralinunshes'°estedodrinedenve\n",
      " gre-glalrengeney gineny masthwheaney y hesgrmerinw-finasathenoxc.\"Gind.\n",
      " tar` menores semonanexaloruala cholexzenenenelalos!alinopunths; pusstonedy Cinetenexalonenellle CDuned Mreblory, I unesPenedy umer\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model5, start_string='There '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 522 steps\n",
      "Epoch 1/15\n",
      "522/522 [==============================] - 39s 75ms/step - loss: 1.8343\n",
      "Epoch 2/15\n",
      "522/522 [==============================] - 40s 77ms/step - loss: 1.2901\n",
      "Epoch 3/15\n",
      "522/522 [==============================] - 41s 78ms/step - loss: 1.1866\n",
      "Epoch 4/15\n",
      "522/522 [==============================] - 39s 74ms/step - loss: 1.1348\n",
      "Epoch 5/15\n",
      "522/522 [==============================] - 38s 73ms/step - loss: 1.0990\n",
      "Epoch 6/15\n",
      "522/522 [==============================] - 38s 74ms/step - loss: 1.0704\n",
      "Epoch 7/15\n",
      "522/522 [==============================] - 39s 74ms/step - loss: 1.0461\n",
      "Epoch 8/15\n",
      "522/522 [==============================] - 39s 74ms/step - loss: 1.0248\n",
      "Epoch 9/15\n",
      "522/522 [==============================] - 38s 73ms/step - loss: 1.0053\n",
      "Epoch 10/15\n",
      "522/522 [==============================] - 39s 74ms/step - loss: 0.9878\n",
      "Epoch 11/15\n",
      "522/522 [==============================] - 39s 74ms/step - loss: 0.9720\n",
      "Epoch 12/15\n",
      "522/522 [==============================] - 39s 74ms/step - loss: 0.9576\n",
      "Epoch 13/15\n",
      "522/522 [==============================] - 41s 79ms/step - loss: 0.9450\n",
      "Epoch 14/15\n",
      "522/522 [==============================] - 40s 76ms/step - loss: 0.9332\n",
      "Epoch 15/15\n",
      "522/522 [==============================] - 41s 78ms/step - loss: 0.9238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x11ddf2046c8>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6 = build_GRU_model(vocab_size=len(unique_chars),\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units,\n",
    "                    batch_size=BATCH_SIZE)\n",
    "model6.compile(optimizer='RMSprop', loss=loss)\n",
    "model6.fit(dataset, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.save_weights('./training_checkpoints/GRU_RSM_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = build_GRU_model(vocab_size=len(unique_chars),\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units,\n",
    "                    batch_size=1)\n",
    "model6.load_weights('./training_checkpoints/GRU_RSM_checkpoint')\n",
    "model6.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There a cloud heavily\n",
      "     canable. Even now--n the key as he pays.\"\n",
      "\n",
      "     \"Oh! I realized that my wife was about to realize of my advice, Watson?\"\n",
      "\n",
      "     I loved all the views, staring otherwise beyond their solurn conversation. They brought no\n",
      "     common man had blown to the stair.\n",
      "\n",
      "     \"That will do,\" said I, \"for we can then take them\n",
      "     at least you are, and that there are time it is\n",
      "     evident that his visit has been entirely drugged to this group.\n",
      "     And then anno name I have the meaning of the facts of mankind chief from the West End. Lawurnil\n",
      "     maid shook his head with his flight.\"\n",
      "\n",
      "     \"And how did he hear a letter you think before. Of course this beautiful\n",
      "     perhaps she has spoken to the spot mixty hobbling but not blowning on to the\n",
      "     Barrymores.\n",
      "\n",
      "     He approached it, and a husband, coming down to conceal it, but gathered through the\n",
      "     whole of that last man this morning.\n",
      "\n",
      "     \"I may add that I had been the moat will find a new mornings at\n",
      "     Baker Street\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model6, start_string='There '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 522 steps\n",
      "Epoch 1/15\n",
      "522/522 [==============================] - 51s 99ms/step - loss: 1.9693 3s - loss: \n",
      "Epoch 2/15\n",
      "522/522 [==============================] - 49s 94ms/step - loss: 1.3399\n",
      "Epoch 3/15\n",
      "522/522 [==============================] - 49s 94ms/step - loss: 1.2106\n",
      "Epoch 4/15\n",
      "522/522 [==============================] - 49s 94ms/step - loss: 1.1490\n",
      "Epoch 5/15\n",
      "522/522 [==============================] - 49s 94ms/step - loss: 1.1088 0s - loss: 1.1\n",
      "Epoch 6/15\n",
      "522/522 [==============================] - 49s 95ms/step - loss: 1.0782\n",
      "Epoch 7/15\n",
      "522/522 [==============================] - 50s 95ms/step - loss: 1.0518\n",
      "Epoch 8/15\n",
      "522/522 [==============================] - 49s 95ms/step - loss: 1.0287\n",
      "Epoch 9/15\n",
      "522/522 [==============================] - 49s 94ms/step - loss: 1.0071\n",
      "Epoch 10/15\n",
      "522/522 [==============================] - 50s 95ms/step - loss: 0.9868 1s - lo - ETA: 0s - loss: \n",
      "Epoch 11/15\n",
      "522/522 [==============================] - 49s 94ms/step - loss: 0.9678\n",
      "Epoch 12/15\n",
      "522/522 [==============================] - 49s 95ms/step - loss: 0.9491\n",
      "Epoch 13/15\n",
      "522/522 [==============================] - 49s 94ms/step - loss: 0.9316\n",
      "Epoch 14/15\n",
      "522/522 [==============================] - 49s 94ms/step - loss: 0.9137\n",
      "Epoch 15/15\n",
      "522/522 [==============================] - 49s 95ms/step - loss: 0.8975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x11de35343c8>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7 = build_LSTM_model(vocab_size=len(unique_chars),\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units,\n",
    "                    batch_size=BATCH_SIZE)\n",
    "\n",
    "model7.compile(optimizer='RMSprop', loss=loss)\n",
    "model7.fit(dataset, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.save_weights('./training_checkpoints/LSTM_RMS_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = build_LSTM_model(vocab_size=len(unique_chars),\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units,\n",
    "                    batch_size=1)\n",
    "model7.load_weights('./training_checkpoints/LSTM_RMS_checkpoint')\n",
    "model7.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There came down to\n",
      "     Rolding's six; but I was a sinking out a slip of paper and the\n",
      "           Rylodes will be back?\"\n",
      "\n",
      "     \"By thumb,\" he said. \"But the lady is sure that you would. You\n",
      "     slipped at a glovely interesting path, and y-- Young October since Dr. Mortimer told\n",
      "     me hell upon so much as material, red before the treasure\n",
      "     is gieaties. As he said, however, otherwise, on which was they\n",
      "     glancing backwaze nor any elecwing girl. It is a stout fanging in front of\n",
      "     yellow-shot, forbidden it is close to me with the auraction of a\n",
      "     large idea that he did.\"\n",
      "\n",
      "     \"You may make it worth this security for?\" asked Holmes.\n",
      "\n",
      "     \"Father--link above. She was told in one of his\n",
      "     met. Even within each business must blame it itsed window of the heavy brows,\n",
      "     and begins to clear it up. With our friend\n",
      "     could lie down without her, but indoors I can.\"\n",
      "\n",
      "     \"What else it is ubout war, for the ladisch door over the walls\n",
      "     t it. And I\n",
      "     think. We must in that\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model7, start_string='There '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 522 steps\n",
      "Epoch 1/15\n",
      "522/522 [==============================] - 39s 74ms/step - loss: 2.5935\n",
      "Epoch 2/15\n",
      "522/522 [==============================] - 38s 72ms/step - loss: 1.7188\n",
      "Epoch 3/15\n",
      "522/522 [==============================] - 37s 72ms/step - loss: 1.5633\n",
      "Epoch 4/15\n",
      "522/522 [==============================] - 37s 71ms/step - loss: 1.4854\n",
      "Epoch 5/15\n",
      "522/522 [==============================] - 38s 72ms/step - loss: 1.4375\n",
      "Epoch 6/15\n",
      "522/522 [==============================] - 37s 72ms/step - loss: 1.4037\n",
      "Epoch 7/15\n",
      "522/522 [==============================] - 37s 72ms/step - loss: 1.3788\n",
      "Epoch 8/15\n",
      "522/522 [==============================] - 37s 72ms/step - loss: 1.3590\n",
      "Epoch 9/15\n",
      "522/522 [==============================] - 38s 72ms/step - loss: 1.3439\n",
      "Epoch 10/15\n",
      "522/522 [==============================] - 37s 71ms/step - loss: 1.3306\n",
      "Epoch 11/15\n",
      "522/522 [==============================] - 37s 72ms/step - loss: 1.3190\n",
      "Epoch 12/15\n",
      "522/522 [==============================] - 38s 72ms/step - loss: 1.3101\n",
      "Epoch 13/15\n",
      "522/522 [==============================] - 38s 72ms/step - loss: 1.3013\n",
      "Epoch 14/15\n",
      "522/522 [==============================] - 38s 72ms/step - loss: 1.2935\n",
      "Epoch 15/15\n",
      "522/522 [==============================] - 37s 71ms/step - loss: 1.2876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x11dc748ee88>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8 = build_RNN_model(vocab_size=len(unique_chars),\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units,\n",
    "                    batch_size=BATCH_SIZE)\n",
    "\n",
    "model8.compile(optimizer='RMSprop', loss=loss)\n",
    "model8.fit(dataset, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8.save_weights('./training_checkpoints/RNN_RMS_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8 = build_RNN_model(vocab_size=len(unique_chars),\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units,\n",
    "                    batch_size=1)\n",
    "model8.load_weights('./training_checkpoints/RNN_RMS_checkpoint')\n",
    "model8.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There all\n",
      "     to but to be disguiseous aspackmissist\n",
      "     know. The\n",
      "     window lodge play she causence that one passive.\"\n",
      "\n",
      "     \"You will would be dark I can Alvarourous oftei. But they took all you, Sir Claimanion. That's\n",
      "     look between from his\n",
      "     atmospage of\n",
      "     the end of them against his hury told your confided job-gover about the\n",
      "     long prescinger which can she was enter off and dumbled\n",
      "     of Afficeales to have you, Souses, and also question had never heard I've back.\n",
      "\n",
      "     \"I know that he had take tracked upon the\n",
      "     last quiting. On the\n",
      "     vague deal him the orders and soul-wream of this!\" Sand-house inspector to started.\n",
      "\n",
      "     \"That is you, Formall\n",
      "     down gales sinctions should have no derately up the\n",
      "     discover the will launch\n",
      "     in the man\n",
      "     admital charactering that\n",
      "     det in an accues marious satually come. I think that he sporting his friendly known house. His own\n",
      "     dars and my alsoftened at, well, and\n",
      "     you will trusting as not with the ins\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model8, start_string='There '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
